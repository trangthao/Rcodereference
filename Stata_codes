## Examining the data
list country* year year pop \\The star after “country” works as a place holder and tells Stata to include all variables that start with “country”
list in 45/49 \\ the observation 45 to 49
list in 50/l \\the observations from 50 until the last observation (lower case L)
list in -10/l \\the last command lists the last ten observations
assert pop>0 \\verifies whether a certain statement is true or false
inspect cgdp \\the distribution of a variable, including as it does a mini-histogram. It is also useful for identifying outliers or unusual values, or for spotting non-integers in a variable that should only contain integers

tabstat #Table of descriptive statistics
Codebook #Show codebook information for file
tab year, sum(pop)
tabstat \\it allows to save the results in special matrices, which can be used for other commands (we learn more about this later)

## Organising datasets 
mvdecode cgdp year pop, mv(-8 -9) \\This will replace all values of -8 and -9 in the three variables with the Stata missing value “.”
drop country_code openc - gdp_growth \\all the variables between openc and gdp_growth are to be dropped
keep if ((year>=1990 & year<=1995) | (year>=1997 & year<=1999))
drop if _n <= 10 \\Dropping observations 1 to 10
drop if _n == _N \\Dropping the last observation (number _N) in the dataset
keep if country[_n] != country[_n-1]
sort country year \\sorts the data by country, and then within each country code it sorts the data by year. This ensures that the first observation for every country (the one that is kept) will be 1950.
                  \\Note that sorting is in ascending order (A,B,C or 1950, 1951, 1952)
gsort –country \\sort in descending order

## By-processing
sort year
by year: sum pop

bysort country: keep if _n == 1 \\keep only the first observation for each country

order *, alphabet
order countrycode year pop, first
order cgdp, after(year)

gen total=_N \\total number of observations
/*A couple of things to note. First, Stata‟s default data type is float, so if you want to create a variable in some other format (e.g.
byte, string), you need to specify this. Second, missing numeric observations, denoted by a dot, are interpreted by Stata as a very
large positive number */
egen totalpop=total(pop), by(year) /* sum of the population per year */
egen avgpop=mean(pop), by(year) /* average country pop per year */
egen maxpop=max(pop) /* largest population value */
egen countpop=count(pop) /* counts number of non-missing obs */
egen groupid=group(country_code) /* generates numeric id variable for countries */

egen totpop=sum(pop) /* sum total of population = single result*/
gen cumpop=sum(pop) /* cumulative total of population */

## Converting strings to numerics and vice versa
encode country, gen(ctyno) \\This creates a new variable ctyno, which takes a value of 1 for CAN, 2 for FRA, and so on. The labels are automatically
                            \\generated, based on the original string values – you can achieve similar results but without the automatic labels using .
egen ctyno=group(country)
codebook ctyno /* Tells you the link with the data* /
decode ctyno, gen(ctycode) \\create a string variable from a numerical one
tostring year, generate(yearcode)
destring yearcode, generate(yearno)


## Combining and dividing variables
gen str7 ctyyear=country_code+yearcode \\joining country code and year to get AGO1950, AGO1951, and so on
gen str2 yr=substr(yearcode,3,2) \\The first term in parentheses is the string variable that you are extracting from, the second is the position of the first character you
                                  \\want to extract (--X-), and the third term is the number of characters to be extracted (--XX)
gen str2 yr=substr(yearcode,-2,2) \\select your starting character by counting from the end (2 positions from the end instead of 3 positions from the start):
gen str10 country=substr(code,1,strpos(code," ")-1) \\ The strpos() function gives the position of the second argument in the first argument, so here it tells you what position the
                                                    \\blank space takes in the code variable. The country substring then extracts from the code variable, starting at the first
                                                    \\character, and extracting a total of 3-1=2 characters for UK, 8-1=7 characters for Ireland and so on.
gen str10 city=trim(substr(code, strpos(code," "),11)) \\The trim() function removes any leading or trailing blanks. So, the city substring extracts from the code variable, starting at the blank
                                                         \\space, and extracting a total of 11 characters including the space, which is then trimmed of

## Dummy variables
xi i.country \\  generates 5 dummy variables, omitting the sixth
encode country, gen(ctyno) \\ factor variables which achieve the same result as xi but avoid the clutter. Unlike xi, factor variables work only on
                           \\numerical variables, so we might have to encode string variables before using factor commands.
sum i.ctyno#i.year \\Using one # tells Stata to ignore the level for each variable and only report the interaction
                   \\Doubling up the #, i.e.i.ctyno##i.year makes the command account for both dummies for each country, each year and each interaction
                   \\category is chosen as base can be manipulated by using ib(z). Rather than i. as prefix. Where z can be first, last, freq
                    \\(for the most frequent category) or #1,#2, etc for the first, second, etc. category
                    
## Lags and leads
so countrycode year
by countrycode: gen lagpop=pop[_n-1] if year==year[_n-1]+1
so country year
by country: gen leadpop=pop[_n+1] if year==year[_n+1]-1 \\a fairly error prone method of accounting for missing

##Fillin and expand
fillin country year \\This creates new missing observations wherever a country-year combination did not previously exist
expand 2 if _n==1 \\creates 2 observations identical to observation number one (_n==1) and places the additional observation at the
                   \\end of the dataset, i.e observation number _N
replace year=1961 if _n==_N
replace pop=. if _n==_N

## Interpolation and extrapolation
so country
by country: ipolate pop year, gen(ipop) \\The first variable listed after the ipolate
                                        \\command is the variable you actually want to interpolate, the second is the dimension along which you want to interpolate
so country
by country: ipolate pop year, gen(ipop) epolate

## Splicing data from an additional source
gen temp1=pop61/pop56 if country==“GER” & year==1970
egen diff=mean(temp1), by(country)
replace pop61=pop56*diff if pop61==. & year<1970

## Imputing missing values from the data
mi set wide
mi register imputed grgdpch
mi register regular kc kg ki openk cgdp pop year \\We will only impute missing values for grgdpch, the other variables are treated as regular variables (even though they might
                                                 \\contain missing values)
mi impute regress grgdpch kc kg ki pop cgdp, add(5) force \\ choose an imputation method and to define the number of repeated samples
mi estimate: regress openk grgdpch kc kg ki pop cgdp, cluster(country) \\ run our estimation (e.g. a regression where
                                                                       \\ we use per capita GDP to explain openness of an economy).
                                                                       \\ we will probably have to make a
                                                                       \\strong assumption on the type of nonrandomness in the missings


## Panel Data Manipulation: Long versus Wide data sets
reshape long pop, i(country_code) j(year) \\from wide to long
                                          \\ in the reshape long case, Stata will reshape all variables that start with the letters you put behind long
                                          \\The i() option specifies the variable(s) whose unique values denote a logical observation in wide format
                                          \\The j() specifies the variable whose unique values denote a sub-observation
                                          \\In long format, i() and j() together completely identify each observation.
reshape wide pop, i(country_code) j(year) \\from long to wide
reshape wide pop, i(year) j(country) string \\you need to specify the string option when j() is a string variable

## Estimation
#d; \\The delimit command changes what Stata perceives as the end of a command. Normally we write one command per line, that is
    \\the end of a line denotes the end of a command as well. #delimit introduces a character – the semicolon (;) – to denote the
    \\end of a command
graph twoway scatter y h,
scheme(s2mono) ytitle("real GDP per worker")
xtitle("average Human Capital in 1995")
note("Source: Penn World Table Version 6.1, Barro and Lee (2001)");
#d c

#d;
graph twoway scatter y h,
scheme(s2mono) ytitle("real GDP per worker")
xtitle("average Human Capital in 1995")
note("Source: Penn World Table Version 6.1, Barro and Lee (2001)"
, margin(medium))
graphregion(fcolor(white) lpattern(solid) lcolor(black) lwidth(medium));
#d cr

#d;
graph twoway
(scatter y h if oecd != 1, mstyle(p1))
(scatter y h if oecd == 1, mstyle(p1) mlabel(iso)) \\To seperate to plots within one graph we can either surround each plot command by
                                                    \\parentheses – () – or use two bars – || –, both are fine. Note that the plots are drawn in the order that we use in the command,
                                                     \\i.e. the first plot will be the backmost and each additional plot will be layered on top of it
, scheme(s2mono) ytitle("real GDP per worker")
xtitle("average Human Capital in 1995")
note("Source: Penn World Table Version 6.1, Barro and Lee (2001)"
, margin(medium))
graphregion(fcolor(white) lpattern(solid) lcolor(black) lwidth(medium))
legend(off);
#d cr
graph save “H:\ECStata\MyFirstGraph”, replace
graph export “H:\ECStata\MyFirstGraph.png”, replace

## Estimation syntax
/* There are many different models of estimation. The main commands include regress, logit, logistic, sureg.
Most have a similar syntax:
command varlist [weight] [if exp] [in range] [, options]
1st variable in the varlist is the dependent variable, and the remaining are the independent variables.
You can use Stata's syntax to specify the estimation sample; you do not have to make a special dataset.
You can, at any time, review the last estimates by typing the estimation command without arguments.
The level() option to indicate the width of the confidence interval. The default is level(95) */

/* post-estimation commands
You can recall the estimates, VCM, standard errors, etc…;
You can carry out hypothesis testing => test (Wald tests), testnl (non-linear Wald tests), lrtest (likelihoodratio tests), hausman (Hausman's specification test);
You can use Stata's predict command, which does predictions and residual calculations.*/

/* weight
sampling weight: pweight - Sampling weights are the inverse sampling probability, that is how many subjects of the
population are represented by the observation
analytic weights: aweight - Analytic weights are appropriate when you run commands on aggregated data. We might
want to run a regression of county level average wages on county characteristics. Analytical weights are then
the number of individuals that are used to calculate the average wage. The reason is that the more
observations are used to calculate the average wage the more precisely the population average wage is
estimated and therefore the more we want to rely on that information. Analytic weights should not be used in
lieu of sampling weights when Stata does not allow the use of sampling weights!
Frequency and importance weights - These two types of weights are less frequently used. Frequency weights are used when
memory is conserved by dropping observations that have exactly the same values in all variables */

/* anova analysis of variance and covariance
cnreg censored-normal regression
gmm Generalized methods of moments estimator
heckman Heckman selection model
intreg interval regression
ivregress instrumental variables (2SLS) regression
newey regression with Newey-West standard errors
prais Prais-Winsten, Cochrane-Orcutt, or Hildreth-Lu regression
qreg quantile (including median) regression
reg ordinary least squares regression
reg3 three-stage least squares regression
rreg robust regression (NOT robust standard errors)
sureg seemingly unrelated regression
tobit tobit regression
treatreg treatment effects model
truncreg truncated regression
xtabond Arellano-Bond linear, dynamic panel-data estimator
xtintreg panel data interval regression models
xtreg fixed- and random-effects linear models
xtregar fixed- and random-effects linear models with an AR(1) disturbance
xttobit panel data tobit models */

regress y k, robust \\The regress command can be used with the robust option for estimating the standard errors using the Huber-White
                    \\sandwich estimator (to correct the standard errors for heteroscedasticity)
regress y k, cluster(country) \\The option cluster(group) allows for arbitrary correlation within specified groups (see Wooldridge, “Econometrics of Cross-Section
                              \\ and Panel Data”, chapter 4, for more details and limitations of this approach).
regress y k
lvr2plot, mlabel(country) \\leverage-versus-residual squared plot). This is not available after the robust option. This plots the leverages of all observations against their squared residuals (the option mlabel labels points according to the
                          \\variable listed in brackets behind it). Leverage tells you how large the influence of a single observation on the estimated
                           \\coefficients is. Observations with high values could potentially be driving the results obtained (especially if they also have a large
                          \\squared residual) so we should check whether excluding them changes anything.

regress y k
avplot k, mlabel(country) \\added-variable plot which graphs the partial correlation between a specified regressor and the dependent variable

## Post-estimation
/* adjust Tables of adjusted means and proportions
estat vce Display covariance matrix of the estimators
estimates Store, replay, display, ... estimation results
hausman Hausman's specification test after model fitting
lincom Obtain linear combinations of coefficients
linktest Specification link test for single-equation models
lrtest Likelihood-ratio test after model fitting
margins Marginal effects or elasticities after estimation
nlcom Nonlinear combinations of estimators
predict Obtain predictions, residuals, etc. after estimation
predictnl Nonlinear predictions after estimation
suest Perform seemingly unrelated estimation
test Test linear hypotheses after estimation
testnl Test nonlinear hypotheses after estimation */

regress y k h if oecd==1
predict y_hat_oecd if oecd==1
predict r_oecd if oecd==1, residual

predict y_hat_oecd_full \\ The if statements are only necessary if you are running the analysis on a subset of dataset currently loaded into Stata. If you
                        \\ want to make out-of-sample predictions, just drop the if statements in the predict commands.
predict r_oecd_full, residual

## Extracting results
regress y k h y1985 ya, robust
gen b_cons=_b[_cons] /* beta coefficient on constant term */
gen b_k=_b[k] /* beta coefficient on GDP60 variable */
gen se_k=_se[k] /* standard error */ 
gen t_k=b_k/se_k \\create a variable containing t-statistics

regress y k h y1985 ya, robust
ereturn list

## OUTREG2 – the ultimate tool in Stata/Latex or Word friendliness?
## outtable, outtex, estout, mat2txt

/* You can find the command by using ssc hot, which shows
the top 10 of commands downloaded in the previous month. */

## Dichotomous dependent variable 
/* When the dependent variable is dichotomous (zero/one), you can run a Linear Probability Model using the regress command.
You may also want to run a logit or a probit regression. The difference between these three models is the assumption that
you make about the probability distribution of the latent dependent variable (LPM assumes an identity function, Logit a logistic
distribution function, and Probit a normal distribution function). */

## Panel Data 
/* 1. Panel data should be kept in long form (with separate person and time variables). However, sometimes your data may
be in wide form and needs to be converted to long form using the reshape command
2. You have to declare your data a panel. One way to do this is using the xtset command. For this, you need two
indicator variables, indicating the unit (panelvar) and time (timevar) dimensions of your panel. In our case, these are
simply year and country. Note that panel dimensions cannot be string variables so you should first encode
country. Once you have done this, use the xtset command */

encode country, gen(country_no)
xtset country_no year

/* xtdes Describe pattern of xt data
xtsum Summarize xt data
xttab Tabulate xt data
xtdata Faster specification searches with xt data
xtline Line plots with xt data
xtreg Fixed-, between- and random-effects, and population-averaged linear models
xtregar Fixed- and random-effects linear models with an AR(1) disturbance
xtgls Panel-data models using GLS
xtpcse OLS or Prais-Winsten models with panel-corrected standard errors
xtrchh Hildreth-Houck random coefficients models
xtivreg Instrumental variables and two-stage least squares for panel-data models
xtabond Arellano-Bond linear, dynamic panel data estimator
xttobit Random-effects tobit models
xtintreg Random-effects interval data regression models
xtlogit Fixed-effects, random-effects, & population-averaged logit models
xtprobit Random-effects and population-averaged probit models
xtcloglog Random-effects and population-averaged cloglog models
xtpoisson Fixed-effects, random-effects, & population-averaged Poisson models
xtnbreg Fixed-effects, random-effects, & population-averaged negative binomial models
xtgee Population-averaged panel-data models using GEE */

## Describe pattern of xt data
xtdes \\to see if your panel is actually balanced or whether there is large variation in the number of years for which
       \\ each cross-sectional unit is reporting
xtdes if cgdp!=.

## Summarize xt data
xtsum pop cgdp \\xtsum is similarly very useful and can be used in the same way that sum is used for non-panel data
                \\s tells us the minimum and maximum, standard deviation and mean (in the overall case) of our selected variables (pop
                \\and cgdp) in three ways that are of interest
                
xttab \\ a generalisation of the tabulate command for panel data and will show overall, within and between variation

## Panel regressions
# Fixed Effects Regression
/* Fixed effects regression controls for unobserved, but constant, variation across the cross-sectional units. It is equivalent to
including a dummy for each country/firm in our regression */
xtreg grgdpch gdp60 openk kc kg ki, fe \\Notice that gdp60, the log of GDP in 1960 for each country, is now dropped as it is constant across time for each country and so is
                                        \\ subsumed by the country fixed-effect

# Between Effects
xtreg grgdpch gdp60 openk kc kg ki, be \\This is equivalent to running a regression on the dataset of means by
                                        \\ cross-sectional identifier. As this results in loss of information, between effects are not used much in practice

# Random Effects
xtreg grgdpch gdp60 openk kc kg ki, re \\Stata's randomeffects estimator is a weighted average of fixed and between effects

# Choosing Between Fixed and Random Effects
/* Choosing between FE and RE models is usually done using a Hausman test, and this is easily completed in Stata using the
Hausman command. To run a Hausman test we need to run the RE and FE models and save the results using the store
command. We then instruct Stata to retrieve the 2 sets of results and carry-out the test */

xtreg grgdpch gdp60 openk kc kg ki, fe
estimates store fe
xtreg grgdpch gdp60 openk kc kg ki, re
estimates store re
hausman fe re \\ the null hypothesis is that there is no difference in the coefficients estimated by the efficient RE
              \\ estimator and the consistent FE estimator. If there is no difference, then use the RE estimator – i.e. if the statistic is insignificant
              \\ that is the Prob>chi2 is larger than .05 or .01. Otherwise, you should use FE, or one of the other solutions for unobserved
               \\ heterogeneity as outlined in your Econometrics lectures
               
# Time series data
tsset datevar
/* tsset Declare a dataset to be time-series data
tsfill Fill in missing times with missing observations in time-series data
tsappend Add observations to a time-series dataset
tsreport Report time-series aspects of a dataset or estimation sample
arima Autoregressive integrated moving-average models
arch Autoregressive conditional heteroskedasticity (ARCH) family of estimators
tssmooth_ma Moving-average filter
tssmooth_nl Nonlinear filter
corrgram Tabulate and graph autocorrelations
xcorr Cross-correlogram for bivariate time series
dfuller Augmented Dickey-Fuller unit-root test
pperron Phillips-Perron unit-roots test
archlm Engle's LM test for the presence of autoregressive conditional heteroskedasticity
var Vector autoregression models
svar Structural vector autoregression models
varbasic Fit a simple VAR and graph impulse-response functions
vec Vector error-correction models
varsoc Obtain lag-order selection statistics for VARs and VECMs
varstable Check the stability condition of VAR or SVAR estimates
vecrank Estimate the cointegrating rank using Johansen's framework
irf create Obtain impulse-response functions and FEVDs
vargranger Perform pairwise Granger causality tests after var or svar
irf graph Graph impulse-response functions and FEVDs
irf cgraph Combine graphs of impulse-response functions and FEVDs
irf ograph Graph overlaid impulse-response functions and FEVDs */

wofd(varname) daily to weekly
mofd(varname) daily to monthly
qofd(varname) daily to quarterly
yofd(varname) daily to yearly

gen daily=date(raw_date,"dmy") 
gen daily=date(raw_date,"dm19y")

weekly(stringvar,"wy")
monthly(stringvar,"my")
quarterly(stringvar,"qy")
halfyearly(stringvar,"hy")
yearly(stringvar,"y")

gen mydate = mdy(month,day,year)
gen year = int(date/10000)
gen month = int((date-year*10000)/100)
gen day = int((date-year*10000-month*100))
gen mydate = mdy(month,day,year)

reg x y if w(1995w9)
sum income if q(1988-3)
tab gender if y(1999)
reg y x if tin(01feb1990,01jun1990) \\t tin() includes the beginning and end dates
sum income if twithin(1988-3,1998-3) \\twithin() excludes them

## Time-series tricks using dates
reg income L.income \\This regresses income(t) on income(t-1)
                    \\ These use the L.varname (to lag) and F.varname (to lead) commands
                     \\If you wanted to lag income by more than one time period, you would simply change the L. to something like "L2." or
                     \\"L3." to lag it by 2 and 3 time periods respectively

\* Used in a similar way, the D.varname command will take the first difference, D2.varname will take the double
difference (difference in difference), etc… *\

\* The S.varname command is similar to the D.varname, except that the difference is always taken from the current
observation to the n-th observation: In other words: S.income=income(t)-income(t-1) and S2.income=income(t)-
income(t-2) *\





## xtdcce2 - Estimating heterogeneous coefficient models using common correlated effects in a dynamic panel with a large number of observations over groups and time periods.
https://janditzen.github.io/xtdcce2/

https://sites.google.com/site/jandger87/stata-code

## xtdcce2
https://janditzen.github.io/xtdcce2/

## xtbreak - estimating and testing for many known and unknown structural breaks in time series and panel data.
https://janditzen.github.io/xtbreak/

## panelview_stata
https://github.com/xuyiqing/panelview_stata

## https://sites.google.com/site/medevecon/code?authuser=0 *****

## Stata guide
https://github.com/skhiggins/Stata_guide

## Stata Coding Practices
https://dimewiki.worldbank.org/Stata_Coding_Practices

## Stata Coding Guide
https://julianreif.com/guide/

## estout - Making regression tables in Stata
http://repec.sowi.unibe.ch/stata/estout/

## Packages for generating LaTeX output from Stata code ***
https://github.com/lukestein/stata-latex-workflows

## Welcome to the Stata Cookbook for Introduction to Data Science
https://github.com/lfkrebs/stata-cookbook

## Mostly Harmless Replication
https://github.com/vikjam/mostly-harmless-replication

## stata-fundamentals **
https://github.com/dlab-berkeley/stata-fundamentals

## Stata_for_Econometrics **
https://github.com/jngod2011/Stata_for_Econometrics

## margins **
https://github.com/leeper/margins

## margins **
http://economicspsychologypolicy.blogspot.com/2014/09/list-of-resources-for-stata-commands.html

## Stata4Econ ****
https://github.com/FanWangEcon/Stata4Econ

## stata-tex: Create custom LaTeX tables from Stata **
https://github.com/FanWangEcon/Stata4Econ

## Econometric-textbook-stata-replication **
https://github.com/Econtech/-Econometric-textbook-stata-replication

## Causal Inference Stata Code
https://github.com/eleanormurray/causalinferencebook_stata

## Blogpost - Nice and fast tables in Stata?
https://github.com/worldbank/stata-tables

## Stata to R *
https://github.com/EconometricsBySimulation/RStata/wiki/Dictionary:-Stata-to-R

## Creating Publication-Quality Tables in Stata **
https://www.ssc.wisc.edu/sscc/pubs/stata_tables.htm

## Causal inference with observational dataCausal inference with observational data
https://www.stata.com/meeting/germany09/nichols.pdf

## Recent Developments in Multilevel Modeling
https://www.stata.com/meeting/6nasug/gutierrez_boston07.pdf

## Panel data methods for microeconometrics using Stata
https://www.stata.com/meeting/wcsug07/cameronwcsug.pdf

## Econometric analysis of dynamic panel-data models
using Stata
https://www.stata.com/meeting/snasug08/drukker_xtdpd.pdf

## Generalized Linear Models
https://data.princeton.edu/wws509/

## Stata to latex
https://statatexblog.com/page/2/

## An Introduction to Modern Econometrics Using Stata
https://www.stata-press.com/books/preview/baum-preview.pdf

## Stata tips
https://medium.com/the-stata-guide/the-awesome-stata-tips-collection-6805afdedffa
https://github.com/asjadnaqvi/The-Stata-Guide

https://github.com/erikgahner/awesome-statistics

## Introduction to Stata ***
https://personal.lse.ac.uk/lembcke/ecStata/2010/MResStataNotesOct2010PartA.pdf 

## Advanced Stata Topics **
https://personal.lse.ac.uk/lembcke/ecStata/2009/MResStataNotesFeb2009PartB.pdf
